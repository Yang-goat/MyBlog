---
icon: book
date: 2025-10-11
order: 1
category:
  - 学习算法
tag:
  - 导论
---

# 学习类算法导论

## 一、什么是"学习"

"学习"本质上是一种**从经验中改进未来决策的过程**。
Mitchell（1997）在经典教材 *Machine Learning* 中下了一个非常简洁的定义：

> 若某个程序在任务 T 上，通过经验 E，使得其在性能度量 P
> 上的表现提高，则称该程序从经验 E 中学习。

换成人话就是：
程序从数据（经验）里提炼规律，以便下一次遇到类似情况时做得更好。

------------------------------------------------------------------------

## 二、学习算法的本质

学习算法是让**机器自动寻找模式**的算法。
它们不是直接写出解决方案，而是**学到一种解决问题的规则**。
可以把它看作一个三要素系统：

- **表示（Representation）**：你用什么形式去表达知识？（比如线性模型、神经网络、树结构......）
- **评估（Evaluation）**：你怎么判断一个模型好不好？（比如损失函数、准确率、奖励值）
- **优化（Optimization）**：你怎么让模型变得更好？（比如梯度下降、遗传算法、策略迭代）

------------------------------------------------------------------------

## 三、学习算法的主要类型

| 类别        | 目标                   | 典型算法                                    | 思想核心                  |
| --------- | -------------------- | --------------------------------------- | --------------------- |
| **监督学习**  | 已知输入与输出，从标注数据中学习映射关系 | 线性回归、SVM、神经网络                           | “模仿老师”——找到最能拟合已知数据的函数 |
| **无监督学习** | 只有输入，没有标签，寻找数据内在结构   | 聚类、PCA、自编码器                             | “自己发现规律”——找相似性、分布结构   |
| **半监督学习** | 结合少量标注与大量未标注数据       | Label Propagation, consistency training | “少量老师+大量自学”           |
| **强化学习**  | 通过与环境交互获得奖励，学习策略     | Q-learning, PPO                         | “试错学习”——行动后得到反馈并改进策略  |
| **自监督学习** | 从数据自身构造训练信号          | BERT, SimCLR                            | “自我造题”——用预测部分数据训练模型   |

## 四、算法背后的哲学

不同算法反映了不同的"学习观"：

- 监督学习：**经验归纳**（从示例中总结规律）
- 强化学习：**行为主义**（通过奖惩塑造策略）
- 无监督学习：**结构主义**（从数据形态中理解世界）
- 深度学习：**连接主义**（知识是分布式表征的结果）

从哲学上讲，所有学习算法都在试图回答一个问题：
\> 如何让"形式系统"获得"经验智慧"？

------------------------------------------------------------------------

## 五、演化趋势

早期机器学习强调"特征工程"与"统计规律"；
后来深度学习让模型直接从数据中**自动抽象特征**；
现在研究正往两个方向扩展：

- **更通用的学习**（如元学习、终身学习、通用智能）
- **更高效的学习**（如小样本学习、强化学习中的探索效率）