import{_ as n,c as o,d as r,o as e}from"./app-MINUdRJW.js";const a={};function i(s,t){return e(),o("div",null,t[0]||(t[0]=[r('<h1 id="学习类算法导论" tabindex="-1"><a class="header-anchor" href="#学习类算法导论"><span>学习类算法导论</span></a></h1><h2 id="一、什么是-学习" tabindex="-1"><a class="header-anchor" href="#一、什么是-学习"><span>一、什么是&quot;学习&quot;</span></a></h2><p>&quot;学习&quot;本质上是一种<strong>从经验中改进未来决策的过程</strong>。<br> Mitchell（1997）在经典教材 <em>Machine Learning</em> 中下了一个非常简洁的定义：</p><blockquote><p>若某个程序在任务 T 上，通过经验 E，使得其在性能度量 P<br> 上的表现提高，则称该程序从经验 E 中学习。</p></blockquote><p>换成人话就是：<br> 程序从数据（经验）里提炼规律，以便下一次遇到类似情况时做得更好。</p><hr><h2 id="二、学习算法的本质" tabindex="-1"><a class="header-anchor" href="#二、学习算法的本质"><span>二、学习算法的本质</span></a></h2><p>学习算法是让<strong>机器自动寻找模式</strong>的算法。<br> 它们不是直接写出解决方案，而是<strong>学到一种解决问题的规则</strong>。<br> 可以把它看作一个三要素系统：</p><ul><li><strong>表示（Representation）</strong>：你用什么形式去表达知识？（比如线性模型、神经网络、树结构......）</li><li><strong>评估（Evaluation）</strong>：你怎么判断一个模型好不好？（比如损失函数、准确率、奖励值）</li><li><strong>优化（Optimization）</strong>：你怎么让模型变得更好？（比如梯度下降、遗传算法、策略迭代）</li></ul><hr><h2 id="三、学习算法的主要类型" tabindex="-1"><a class="header-anchor" href="#三、学习算法的主要类型"><span>三、学习算法的主要类型</span></a></h2><table><thead><tr><th>类别</th><th>目标</th><th>典型算法</th><th>思想核心</th></tr></thead><tbody><tr><td><strong>监督学习</strong></td><td>已知输入与输出，从标注数据中学习映射关系</td><td>线性回归、SVM、神经网络</td><td>“模仿老师”——找到最能拟合已知数据的函数</td></tr><tr><td><strong>无监督学习</strong></td><td>只有输入，没有标签，寻找数据内在结构</td><td>聚类、PCA、自编码器</td><td>“自己发现规律”——找相似性、分布结构</td></tr><tr><td><strong>半监督学习</strong></td><td>结合少量标注与大量未标注数据</td><td>Label Propagation, consistency training</td><td>“少量老师+大量自学”</td></tr><tr><td><strong>强化学习</strong></td><td>通过与环境交互获得奖励，学习策略</td><td>Q-learning, PPO</td><td>“试错学习”——行动后得到反馈并改进策略</td></tr><tr><td><strong>自监督学习</strong></td><td>从数据自身构造训练信号</td><td>BERT, SimCLR</td><td>“自我造题”——用预测部分数据训练模型</td></tr></tbody></table><h2 id="四、算法背后的哲学" tabindex="-1"><a class="header-anchor" href="#四、算法背后的哲学"><span>四、算法背后的哲学</span></a></h2><p>不同算法反映了不同的&quot;学习观&quot;：</p><ul><li>监督学习：<strong>经验归纳</strong>（从示例中总结规律）</li><li>强化学习：<strong>行为主义</strong>（通过奖惩塑造策略）</li><li>无监督学习：<strong>结构主义</strong>（从数据形态中理解世界）</li><li>深度学习：<strong>连接主义</strong>（知识是分布式表征的结果）</li></ul><p>从哲学上讲，所有学习算法都在试图回答一个问题：<br> &gt; 如何让&quot;形式系统&quot;获得&quot;经验智慧&quot;？</p><hr><h2 id="五、演化趋势" tabindex="-1"><a class="header-anchor" href="#五、演化趋势"><span>五、演化趋势</span></a></h2><p>早期机器学习强调&quot;特征工程&quot;与&quot;统计规律&quot;；<br> 后来深度学习让模型直接从数据中<strong>自动抽象特征</strong>；<br> 现在研究正往两个方向扩展：</p><ul><li><strong>更通用的学习</strong>（如元学习、终身学习、通用智能）</li><li><strong>更高效的学习</strong>（如小样本学习、强化学习中的探索效率）</li></ul>',20)]))}const l=n(a,[["render",i]]),g=JSON.parse('{"path":"/ai-ml/Introduction-to-Learning-Algorithms.html","title":"学习类算法导论","lang":"zh-CN","frontmatter":{"icon":"book","date":"2025-10-11T00:00:00.000Z","order":1,"category":["学习算法"],"tag":["导论"],"description":"学习类算法导论 一、什么是\\"学习\\" \\"学习\\"本质上是一种从经验中改进未来决策的过程。 Mitchell（1997）在经典教材 Machine Learning 中下了一个非常简洁的定义： 若某个程序在任务 T 上，通过经验 E，使得其在性能度量 P 上的表现提高，则称该程序从经验 E 中学习。 换成人话就是： 程序从数据（经验）里提炼规律，以便下一次遇...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"学习类算法导论\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-10-11T00:00:00.000Z\\",\\"dateModified\\":\\"2025-10-17T15:13:33.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Goat_Yang\\",\\"url\\":\\"../intro.html\\"}]}"],["meta",{"property":"og:url","content":"https://github.com/Yang-goat/MyBlog/ai-ml/Introduction-to-Learning-Algorithms.html"}],["meta",{"property":"og:site_name","content":"Goat_Yang"}],["meta",{"property":"og:title","content":"学习类算法导论"}],["meta",{"property":"og:description","content":"学习类算法导论 一、什么是\\"学习\\" \\"学习\\"本质上是一种从经验中改进未来决策的过程。 Mitchell（1997）在经典教材 Machine Learning 中下了一个非常简洁的定义： 若某个程序在任务 T 上，通过经验 E，使得其在性能度量 P 上的表现提高，则称该程序从经验 E 中学习。 换成人话就是： 程序从数据（经验）里提炼规律，以便下一次遇..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-10-17T15:13:33.000Z"}],["meta",{"property":"article:tag","content":"导论"}],["meta",{"property":"article:published_time","content":"2025-10-11T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-10-17T15:13:33.000Z"}]]},"git":{"createdTime":1760276044000,"updatedTime":1760714013000,"contributors":[{"name":"Yang-goat","username":"Yang-goat","email":"1700425119@qq.com","commits":2,"url":"https://github.com/Yang-goat"}]},"readingTime":{"minutes":2.42,"words":727},"filePathRelative":"ai-ml/Introduction-to-Learning-Algorithms.md","excerpt":"\\n<h2>一、什么是\\"学习\\"</h2>\\n<p>\\"学习\\"本质上是一种<strong>从经验中改进未来决策的过程</strong>。<br>\\nMitchell（1997）在经典教材 <em>Machine Learning</em> 中下了一个非常简洁的定义：</p>\\n<blockquote>\\n<p>若某个程序在任务 T 上，通过经验 E，使得其在性能度量 P<br>\\n上的表现提高，则称该程序从经验 E 中学习。</p>\\n</blockquote>\\n<p>换成人话就是：<br>\\n程序从数据（经验）里提炼规律，以便下一次遇到类似情况时做得更好。</p>\\n<hr>\\n<h2>二、学习算法的本质</h2>","autoDesc":true}');export{l as comp,g as data};
